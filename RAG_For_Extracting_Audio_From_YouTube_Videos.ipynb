{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dd7c4c87",
      "metadata": {
        "id": "dd7c4c87"
      },
      "source": [
        "# Retrieval-Augmented Generation (RAG) For Extracting and Transcribing Audio From Public YouTube Videos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "This project demonstrates a Retrieval-Augmented Generation (RAG) pipeline that extracts and transcribes audio from public YouTube videos, indexes the transcript using LlamaIndex, and enables querying using OpenAI's GPT-4. It forms the base for a multimodal RAG system for including visual content in future project."
      ],
      "metadata": {
        "id": "IISpnp77gPQ1"
      },
      "id": "IISpnp77gPQ1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eUQLkYQqfhRo"
      },
      "id": "eUQLkYQqfhRo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"your-path-here\""
      ],
      "metadata": {
        "id": "3Q5hQvSIfkaV"
      },
      "id": "3Q5hQvSIfkaV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Dependencies\n",
        "%%capture\n",
        "!pip install -U llama-index openai yt-dlp git+https://github.com/openai/whisper.git youtube-transcript-api"
      ],
      "metadata": {
        "id": "p79gGfsizBtX"
      },
      "id": "p79gGfsizBtX",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "id": "GhhnjBuaBUV6"
      },
      "id": "GhhnjBuaBUV6",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import openai\n",
        "import whisper\n",
        "import tempfile\n",
        "import yt_dlp\n",
        "from IPython.display import Audio, Markdown, display\n",
        "\n",
        "# LlamaIndex v0.10+ Imports\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n"
      ],
      "metadata": {
        "id": "KqNcNSXwzBwM"
      },
      "id": "KqNcNSXwzBwM",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "metadata": {
        "id": "xNcGHEdlGnr1"
      },
      "id": "xNcGHEdlGnr1",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup OpenAI API\n",
        "openai.api_key = \"your-OpenAI-API-key-here\""
      ],
      "metadata": {
        "id": "BuQjm1PvzByi"
      },
      "id": "BuQjm1PvzByi",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure OpenAI model (GPT-4 Turbo)\n",
        "Settings.llm = OpenAI(model=\"gpt-4-0125-preview\") # replace with a model of your choice\n",
        "Settings.embed_model = OpenAIEmbedding()"
      ],
      "metadata": {
        "id": "ew37ga2kG6ZG"
      },
      "id": "ew37ga2kG6ZG",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download YouTube Audio\n",
        "def download_youtube_audio(url, output_dir):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'outtmpl': os.path.join(output_dir, '%(id)s.%(ext)s'),\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "    }\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        info_dict = ydl.extract_info(url, download=True)\n",
        "        video_id = info_dict.get(\"id\", None)\n",
        "        return os.path.join(output_dir, f\"{video_id}.mp3\")"
      ],
      "metadata": {
        "id": "Jmws-_3yzB1Z"
      },
      "id": "Jmws-_3yzB1Z",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transcribe Audio\n",
        "model = whisper.load_model(\"base\")"
      ],
      "metadata": {
        "id": "gbGigHb9A_UO"
      },
      "id": "gbGigHb9A_UO",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio(audio_path):\n",
        "    result = model.transcribe(audio_path)\n",
        "    return result[\"text\"]"
      ],
      "metadata": {
        "id": "8GF00i2ZBCcK"
      },
      "id": "8GF00i2ZBCcK",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save transcript to file\n",
        "def save_transcript(text, filename):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(text)"
      ],
      "metadata": {
        "id": "HEGiXj1QB7xb"
      },
      "id": "HEGiXj1QB7xb",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Index from transcript with chunk control\n",
        "\n",
        "def build_index_from_transcript(transcript_file):\n",
        "    documents = SimpleDirectoryReader(input_files=[transcript_file]).load_data()\n",
        "    parser = SimpleNodeParser.from_defaults(chunk_size=256, chunk_overlap=20)\n",
        "    nodes = parser.get_nodes_from_documents(documents)\n",
        "    index = VectorStoreIndex(nodes)\n",
        "    return index\n"
      ],
      "metadata": {
        "id": "Qo0Bsr9hB_eA"
      },
      "id": "Qo0Bsr9hB_eA",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query the index with a prompt\n",
        "\n",
        "def query_index(index, question):\n",
        "    query_engine = index.as_query_engine()\n",
        "    return query_engine.query(question)"
      ],
      "metadata": {
        "id": "6GQtXZ0EB_g2"
      },
      "id": "6GQtXZ0EB_g2",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Download and transcribe YouTube video\n",
        "video_url = \"https://www.youtube.com/watch?v=7Hcg-rLYwdM\"  # Replace with your video\n",
        "with tempfile.TemporaryDirectory() as tmpdir:\n",
        "    audio_path = download_youtube_audio(video_url, tmpdir)\n",
        "    print(\"\\n✅ Audio downloaded:\", audio_path)\n",
        "    transcript = transcribe_audio(audio_path)\n",
        "    transcript_file = os.path.join(tmpdir, \"transcript.txt\")\n",
        "    save_transcript(transcript, transcript_file)\n",
        "\n",
        "    # Step 2: Build RAG index\n",
        "    index = build_index_from_transcript(transcript_file)\n",
        "\n",
        "    # Step 3: Query with prompt\n",
        "    prompt = (\n",
        "        \"Summarize the key takeaways in bullet points using markdown format. \"\n",
        "        \"Highlight important topics in bold and include emotional or reflective aspects if mentioned.\"\n",
        "    )\n",
        "    response = query_index(index, prompt)\n",
        "\n",
        "    # Step 4: Display formatted Markdown response\n",
        "    display(Markdown(str(response)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "cttJLp1-B_jL",
        "outputId": "cde774d8-298d-49ef-a923-2dce54ac7c34"
      },
      "id": "cttJLp1-B_jL",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=7Hcg-rLYwdM\n",
            "[youtube] 7Hcg-rLYwdM: Downloading webpage\n",
            "[youtube] 7Hcg-rLYwdM: Downloading tv client config\n",
            "[youtube] 7Hcg-rLYwdM: Downloading player 20830619\n",
            "[youtube] 7Hcg-rLYwdM: Downloading tv player API JSON\n",
            "[youtube] 7Hcg-rLYwdM: Downloading ios player API JSON\n",
            "[youtube] 7Hcg-rLYwdM: Downloading m3u8 information\n",
            "[info] 7Hcg-rLYwdM: Downloading 1 format(s): 251\n",
            "[download] Destination: /tmp/tmpf1hkdyix/7Hcg-rLYwdM.webm\n",
            "[download] 100% of    1.42MiB in 00:00:00 at 21.27MiB/s  \n",
            "[ExtractAudio] Destination: /tmp/tmpf1hkdyix/7Hcg-rLYwdM.mp3\n",
            "Deleting original file /tmp/tmpf1hkdyix/7Hcg-rLYwdM.webm (pass -k to keep)\n",
            "\n",
            "✅ Audio downloaded: /tmp/tmpf1hkdyix/7Hcg-rLYwdM.mp3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- **Participation in science activities**: The speaker reflects on being proud of participating in various science activities during their mission on the International Space Station over the last two months.\n- **Spacewalks**: Expresses surprise and joy at having the opportunity to conduct four additional spacewalks, describing it as \"icing on the cake\" for the mission.\n- **Expedition 63**: The speaker was a part of Expedition 63, indicating a specific mission or time frame during their stay on the International Space Station.\n- **Memorable experience**: Describes the mission as a lifetime memory and a true honor, highlighting the emotional and reflective aspect of their experience.\n- **SpaceX Dragon undocking**: Mentions the undocking sequence commanded for Dragon SpaceX, indicating the spacecraft used for their return journey.\n- **Importance of safe return**: Emphasizes that the hardest part of the mission was the launch, but the most crucial part was safely returning home.\n- **Personal message**: Includes a personal message (\"I've been trying, Daddy. We love you. Hurry home for weeks and don't get my dog. Slashed out.\"), suggesting a communication with family, showing the emotional side of space missions.\n- **Successful return to Earth**: Concludes with a successful return to Earth after a 19-hour journey, with a welcoming message from SpaceX, and a note on the astronauts being back on Earth, referred to as \"space dads.\""
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}